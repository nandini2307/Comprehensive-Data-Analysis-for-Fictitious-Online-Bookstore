{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Comprehensive Data Analysis for Fictitious Online Bookstore"
      ],
      "metadata": {
        "id": "2ikbvrVxAxw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATASETS"
      ],
      "metadata": {
        "id": "FIcAbNIhA0rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9s-7KJQ5NAn",
        "outputId": "68c7499f-1ed9-4972-98a7-7784e673bdf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-25.8.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Installing collected packages: faker\n",
            "Successfully installed faker-25.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis on Customer Reviews"
      ],
      "metadata": {
        "id": "_iTbOJwQA2w2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfjgdZAA5Dlt",
        "outputId": "013f944d-bf9d-4250-cb86-b51bc0917636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with 10,000 records created and saved as 'customer_reviews.csv'.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Parameters\n",
        "num_records = 10000\n",
        "num_unique_books = 10000  # Each record will have a unique book title, author, and genre\n",
        "\n",
        "# Generate unique book titles, authors, and genres\n",
        "book_titles = [fake.sentence(nb_words=4) for _ in range(num_unique_books)]\n",
        "authors = [fake.name() for _ in range(num_unique_books)]\n",
        "genres = [fake.word(ext_word_list=[\"Mystery\", \"Self-help\", \"Science Fiction\", \"Romance\", \"Cooking\"]) for _ in range(num_unique_books)]\n",
        "ratings = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Generate data\n",
        "data = {\n",
        "    \"ReviewID\": range(1, num_records + 1),\n",
        "    \"BookID\": [random.randint(1001, 11000) for _ in range(num_records)],\n",
        "    \"BookTitle\": [random.choice(book_titles) for _ in range(num_records)],\n",
        "    \"Author\": [random.choice(authors) for _ in range(num_records)],\n",
        "    \"Genre\": [random.choice(genres) for _ in range(num_records)],\n",
        "    \"ReviewText\": [fake.text(max_nb_chars=200) for _ in range(num_records)],\n",
        "    \"Rating\": [random.choice(ratings) for _ in range(num_records)],\n",
        "}\n",
        "\n",
        "reviews_df = pd.DataFrame(data)\n",
        "reviews_df.to_csv(\"customer_reviews.csv\", index=False)\n",
        "\n",
        "print(\"Dataset with 10,000 records created and saved as 'customer_reviews.csv'.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Customer Churn Analysis"
      ],
      "metadata": {
        "id": "Xz8zUW84A61B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from faker import Faker\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Parameters\n",
        "num_customers = 10000\n",
        "\n",
        "# Generate data\n",
        "data = {\n",
        "    \"CustomerID\": range(1, num_customers + 1),\n",
        "    \"Age\": np.random.randint(18, 70, size=num_customers),\n",
        "    \"Gender\": np.random.choice([\"M\", \"F\"], size=num_customers),\n",
        "    \"Location\": [f\"{fake.city()}, {fake.state()}\" for _ in range(num_customers)],\n",
        "    \"PurchaseFrequency\": np.random.randint(1, 20, size=num_customers),\n",
        "    \"AvgOrderValue\": np.round(np.random.uniform(10, 200, size=num_customers), 2),\n",
        "    \"TimeSinceLastPurchase\": np.random.randint(1, 365, size=num_customers),\n",
        "    \"Churn\": np.random.choice([0, 1], size=num_customers),\n",
        "}\n",
        "\n",
        "churn_df = pd.DataFrame(data)\n",
        "churn_df.to_csv(\"customer_churn.csv\", index=False)\n",
        "\n",
        "print(\"Dataset with 10,000 records created and saved as 'customer_churn.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWdda3d85JHD",
        "outputId": "9c134321-8cd8-4410-d082-8afc77ab9819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset with 10,000 records created and saved as 'customer_churn.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Employee Retention Analysis"
      ],
      "metadata": {
        "id": "7lm-6M5bA9eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "num_employees = 10000\n",
        "departments = [\"Sales\", \"IT\", \"HR\", \"Marketing\", \"Finance\"]\n",
        "yes_no = [\"Yes\", \"No\"]\n",
        "\n",
        "# Generate data\n",
        "data = {\n",
        "    \"EmployeeID\": range(1, num_employees + 1),\n",
        "    \"Age\": np.random.randint(18, 65, size=num_employees),\n",
        "    \"Gender\": np.random.choice([\"M\", \"F\"], size=num_employees),\n",
        "    \"Department\": [random.choice(departments) for _ in range(num_employees)],\n",
        "    \"Tenure\": np.random.randint(1, 10, size=num_employees),\n",
        "    \"PerformanceScore\": np.round(np.random.uniform(1, 5, size=num_employees), 1),\n",
        "    \"JobSatisfaction\": np.round(np.random.uniform(1, 5, size=num_employees), 1),\n",
        "    \"EngagementScore\": np.round(np.random.uniform(1, 5, size=num_employees), 1),\n",
        "    \"TrainingHours\": np.random.randint(0, 100, size=num_employees),\n",
        "    \"PromotionLastYear\": [random.choice(yes_no) for _ in range(num_employees)],\n",
        "    \"Turnover\": np.random.choice([0, 1], size=num_employees),\n",
        "}\n",
        "\n",
        "employees_df = pd.DataFrame(data)\n",
        "employees_df.to_csv(\"employee_retention.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "gW_Ouexh6ZSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sales Forecasting"
      ],
      "metadata": {
        "id": "3HmxycV6BBh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Parameters\n",
        "start_date = datetime(2020, 1, 1)\n",
        "end_date = datetime(2024, 6, 20)\n",
        "date_range = pd.date_range(start_date, end_date)\n",
        "num_days = len(date_range)\n",
        "num_books = 5\n",
        "promotion_flags = [True, False]\n",
        "seasons = [\"Winter\", \"Spring\", \"Summer\", \"Fall\"]\n",
        "\n",
        "# Generate data\n",
        "# Use np.tile for 'BookID' and 'BookTitle' to match the length of 'Date'\n",
        "\n",
        "dates = np.tile(date_range, num_books)\n",
        "np.random.shuffle(dates)\n",
        "\n",
        "data = {\n",
        "    \"Date\": dates,\n",
        "    \"BookID\": np.tile([random.randint(1001, 11000) for _ in range(num_books)], num_days),  # Tile BookID to match Date length\n",
        "    \"BookTitle\": np.tile(book_titles[:num_books], num_days),  # Changed to np.tile, sliced book_titles to match num_books\n",
        "    \"DailySales\": np.random.randint(1, 50, size=num_days * num_books),\n",
        "    \"Promotions\": np.random.choice(promotion_flags, size=num_days * num_books),\n",
        "    \"Season\": [seasons[pd.Timestamp(d).month % 12 // 3] for d in np.tile(date_range, num_books)],\n",
        "}\n",
        "\n",
        "sales_df = pd.DataFrame(data)\n",
        "sales_df.to_csv(\"sales_forecasting.csv\", index=False)"
      ],
      "metadata": {
        "id": "V7wHZP0764Qm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}